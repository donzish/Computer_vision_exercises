{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "E02_donzella_marco_829358.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GcUdBbQq3Heg"
      },
      "source": [
        "# Assignement E02 - DSIM\n",
        "\n",
        "*Marco Donzella 829358* "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implement the Zero-Crossing Rate (ZCR) feature to describe a single-channel audio signal, starting from the commands shown during the laboratory.\n",
        "\n",
        "Rules:\n",
        "\n",
        "1. Show the effects on classification performance for the dataset \"free-spoken-digit-dataset\" (recordings.tar).\n",
        "2. Verify the effect of using ZCR in combination with other features available in the published notebook.\n",
        "3. Using libraries such as Librosa is not allowed, as they offer pre-made functions to compute ZCR.\n",
        "4. It is, instead, possible to use numpy for the basic operations (shift, sign, etc.).\n",
        "5. Many variations of ZCR exist and will be accepted: whenever you make arbitrary decisions in the implementation, just describe them in the submission.\n",
        "\n",
        "Submission:\n",
        "\n",
        "1. Notebook with well-commented steps and observations on the results.\n",
        "2. If you submit a .py script instead of a notebook, attach a short report for the observations on the results.\n",
        "3. Name the submitted file as: E02_surname_name_studentID"
      ],
      "metadata": {
        "id": "ISKVcRh2fRg5"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5arER6tbDMC2"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from time import time\n",
        "from scipy.io import wavfile as wav\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import IPython.display as ipd\n",
        "\n",
        "# Classification tools\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# File management\n",
        "from google.colab import drive\n",
        "import tarfile\n",
        "from shutil import copyfile\n",
        "\n",
        "# Advanced audio features\n",
        "import librosa\n",
        "import librosa.display as lid\n",
        "from sklearn.preprocessing import scale"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Carichiamo il dataset di interesse collegando il notebook all'account drive."
      ],
      "metadata": {
        "id": "S6GVI3o50AJA"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aphhmxgs6Phz",
        "outputId": "5fad651a-32e9-4cf5-c330-ba84200c2cb8"
      },
      "source": [
        "drive.mount('/content/gdrive') # i file sono solo visibili"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvZ40fDo6TYy"
      },
      "source": [
        "copyfile('gdrive/MyDrive/Digital Signal and Image Management/lezione 2/recordings.tar','recordings.tar')\n",
        "tar = tarfile.open('recordings.tar')\n",
        "tar.extractall()\n",
        "tar.close() # i file sono stati estratti"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data loader\n",
        "\n",
        "- Il dataset viene caricato\n",
        "- Viene estratta la classe specificata nel nome del file\n",
        "- Le tracce audio vengono divise in training set e test set\n",
        "- I dati vengono normalizzati "
      ],
      "metadata": {
        "id": "jqx-vjtq0hhm"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpM3ELjfFGfI"
      },
      "source": [
        "# Placecholder for feature extractor\n",
        "def identity(input):\n",
        "    return input\n",
        "\n",
        "# Data loader\n",
        "def load_data(feature_extractor=identity, normalize=False):\n",
        "\n",
        "    labels = []\n",
        "    features = []\n",
        "\n",
        "    for f in sorted(os.listdir('./recordings')):\n",
        "        if f.endswith('.wav'):\n",
        "            # Load file and compute the requested features\n",
        "            _, signal = wav.read('./recordings/' + f)\n",
        "            cur_features = feature_extractor(signal)\n",
        "            features.append(cur_features)\n",
        "\n",
        "            # Classes\n",
        "            label = f.split('_')[0]\n",
        "            labels.append(label)\n",
        "\n",
        "    # X: features, y: labels\n",
        "    X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.1, random_state=1)\n",
        "\n",
        "    if normalize: # è una standardizzazione\n",
        "        eps = 0.001\n",
        "        X_train = np.array(X_train)\n",
        "        X_train_mean = X_train.mean(axis=0)\n",
        "        X_train_std = X_train.std(axis=0)\n",
        "        X_train = (X_train - X_train_mean + eps)/(X_train_std + eps)\n",
        "        X_train = [row for row in X_train]\n",
        "\n",
        "        X_test = [row for row in (np.array(X_test) - X_train_mean + eps)/(X_train_std + eps)]\n",
        "\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "# Main\n",
        "if __name__ == '__main__':\n",
        "\tX_train, X_test, y_train, y_test = load_data()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ZCR"
      ],
      "metadata": {
        "id": "18sXQIdf1m0k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Viene definita la funzione zcr2 per calcolare il zero crossing rate di un segnale audio. Tale funzione è stata definita supponendo che il segnale audio fosse ciclico e dunque si ripetesse (in questo modo il primo valore del segnale audio originale occuperà l'ultima posizione nel segnale audio traslato).\n",
        "\n",
        "*È riportato di seguito un link con un approfondimento della zero crossing rate e della relativa formula sotto implementata:\n",
        "https://www.sciencedirect.com/topics/engineering/zero-crossing-rate#:~:text=The%20ZCR%20is%20defined%20according,xi(n)%3C0.*"
      ],
      "metadata": {
        "id": "HARRh53Wo61h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def zcr2(input):\n",
        "  sign = np.sign(input) # segno dell'input originale\n",
        "  sign_t = np.sign(np.roll(input,-1)) # segno dell'input traslato di 1 (il primo valore dell'input originale occupa dunque l'ultima posizione)\n",
        "  value = 1/(2*len(input)) * np.sum(abs(sign - sign_t), keepdims=True) # valore di zcr\n",
        "  return value"
      ],
      "metadata": {
        "id": "-Xf3YE_WyhFV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SVM - primo approccio\n",
        "\n",
        "In questa prima fase viene utilizzata solo la feature definita prima per estrarre i dati."
      ],
      "metadata": {
        "id": "Kdo5cscw3Mr2"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUJTZm3_HFb6"
      },
      "source": [
        "X_train, X_test, y_train, y_test = load_data(feature_extractor=zcr2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Si procede dunque addestrando il classificatore SVM:"
      ],
      "metadata": {
        "id": "zauh3r_c4hw6"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zY1il9DzJofH"
      },
      "source": [
        "clf = SVC(kernel='rbf', class_weight='balanced')\n",
        "clf = clf.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCRJhsR8LQf0"
      },
      "source": [
        "y_pred = clf.predict(X_test) # y cappuccio"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MypGdzEHLb1M",
        "outputId": "92219bcf-f8e6-4192-9a11-6bc9c7efd17c"
      },
      "source": [
        "print(classification_report(y_test, y_pred)) # performance del classificatore"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.29      0.71      0.41        17\n",
            "           1       0.00      0.00      0.00        10\n",
            "           2       0.29      0.13      0.18        15\n",
            "           3       0.00      0.00      0.00        19\n",
            "           4       0.17      0.64      0.27        11\n",
            "           5       0.19      0.50      0.28        14\n",
            "           6       0.92      0.79      0.85        14\n",
            "           7       0.00      0.00      0.00        19\n",
            "           8       0.31      0.24      0.27        17\n",
            "           9       0.00      0.00      0.00        14\n",
            "\n",
            "    accuracy                           0.29       150\n",
            "   macro avg       0.22      0.30      0.23       150\n",
            "weighted avg       0.21      0.29      0.22       150\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "drJrK-YB3I6f",
        "outputId": "1ab1aeca-ccae-485c-bc5c-228a1390ab6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[12  0  0  0  4  1  0  0  0  0]\n",
            " [ 6  0  0  0  3  1  0  0  0  0]\n",
            " [ 2  0  2  0  2  7  0  0  2  0]\n",
            " [ 7  0  1  0  6  5  0  0  0  0]\n",
            " [ 3  0  0  0  7  1  0  0  0  0]\n",
            " [ 2  0  1  0  1  7  0  0  3  0]\n",
            " [ 0  0  1  0  1  1 11  0  0  0]\n",
            " [ 3  0  1  0  2  8  1  0  4  0]\n",
            " [ 0  0  1  0  9  3  0  0  4  0]\n",
            " [ 7  0  0  0  5  2  0  0  0  0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Il classificatore è caratterizzato da un'Accuracy pari a 0.29. Le performance non sono buone e questo è evidente anche dalla matrice di confusione, che presenta diverse valori al di fuori della diagonale principale.\n",
        "Si decide dunque di provare a migliorare il metodo di estrazione dati, andando a combinare la funzione zcr2 creata precedentemente con altre funzioni."
      ],
      "metadata": {
        "id": "FOdBRe3i4tu4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Features"
      ],
      "metadata": {
        "id": "yPfQjqKQ35OQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vengono implementate altre features, da combinare alla zero crossing rate vista precedentemente, per ottenere una migliore interpretazione dei dati e, di conseguenza, migliori performance del classificatore."
      ],
      "metadata": {
        "id": "GzoRJNy76TJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def aavg(input): # media dei valori assoluti del segnale audio\n",
        "    return np.mean(np.abs(input), keepdims=True)"
      ],
      "metadata": {
        "id": "6M7YpxnN4SB2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def duration(input): # durata del segnale audio\n",
        "    return input.shape"
      ],
      "metadata": {
        "id": "VE2ljW4I4sGP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def energy(input): # energia del segnale audio\n",
        "    return np.sum((input*1.0)**2, keepdims=True)"
      ],
      "metadata": {
        "id": "uvcclTSl4vZ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sdev(input): # deviazione standard del segnale audio\n",
        "    return np.std(input, keepdims=True)"
      ],
      "metadata": {
        "id": "OJD9nDWL4yOE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def combo(input): # combinazione di tutte le features descritte prima (+ zero crossing rate)\n",
        "    return np.concatenate((aavg(input),sdev(input),duration(input),energy(input),zcr2(input)))"
      ],
      "metadata": {
        "id": "lyVhXF_654q9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model training\n",
        "\n",
        "Per ottenere performance migliori, per estrarre i dati vengono utilizzate tutte le feautures viste prima ed inoltre viene anche aggiunto il parametro di normalizzazione (normalize=True)."
      ],
      "metadata": {
        "id": "9ehZVBIJ5rc-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = load_data(feature_extractor=combo, normalize=True)"
      ],
      "metadata": {
        "id": "EuOEf5od5tfW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Una parte del dataset di training viene utilizzata come validation set per stimare i parametri *C* e *gamma* e migliorare ulteriormente il modello:"
      ],
      "metadata": {
        "id": "FBMAWPdB6jyx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters to be tested in cross-validation\n",
        "param_grid = {'C': [1e2, 5e2, 1e3],\n",
        "          'gamma': [0.005, 0.01, 0.1, 0.5, 1.0], }\n",
        "\n",
        "clf = GridSearchCV(SVC(kernel='rbf', class_weight='balanced'), param_grid, cv=2)\n",
        "clf = clf.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "dcAYZy2B6Xkw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Migliori parametri stimati:')\n",
        "print(' C: '+str(clf.best_estimator_.C))\n",
        "print(' gamma: '+str(clf.best_estimator_.gamma))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z6VOcMQ-7AWT",
        "outputId": "1498d9a7-7a83-4083-af94-fbd7b0434a6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Migliori parametri stimati:\n",
            " C: 100.0\n",
            " gamma: 0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model testing"
      ],
      "metadata": {
        "id": "UOctQjEJ7FK7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Classificaiton report\n",
        "print('Classification report:')\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Confusion matrix\n",
        "print('Confusion matrix:')\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(cm)\n",
        "plt.imshow(cm, cmap=plt.cm.Blues)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 786
        },
        "id": "ciSZzH907Maj",
        "outputId": "8b697923-fa5e-4989-f899-01bd285084b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.65      0.76        17\n",
            "           1       0.47      0.80      0.59        10\n",
            "           2       0.60      0.60      0.60        15\n",
            "           3       0.85      0.58      0.69        19\n",
            "           4       0.44      0.73      0.55        11\n",
            "           5       0.50      0.64      0.56        14\n",
            "           6       0.87      0.93      0.90        14\n",
            "           7       0.78      0.37      0.50        19\n",
            "           8       0.50      0.53      0.51        17\n",
            "           9       0.73      0.79      0.76        14\n",
            "\n",
            "    accuracy                           0.64       150\n",
            "   macro avg       0.67      0.66      0.64       150\n",
            "weighted avg       0.69      0.64      0.64       150\n",
            "\n",
            "Confusion matrix:\n",
            "[[11  0  3  0  0  0  0  0  0  3]\n",
            " [ 0  8  0  0  2  0  0  0  0  0]\n",
            " [ 0  1  9  1  0  2  1  0  1  0]\n",
            " [ 0  3  2 11  1  2  0  0  0  0]\n",
            " [ 0  2  1  0  8  0  0  0  0  0]\n",
            " [ 0  0  0  0  3  9  0  1  1  0]\n",
            " [ 0  0  0  0  0  0 13  0  1  0]\n",
            " [ 0  1  0  0  1  3  0  7  6  1]\n",
            " [ 0  2  0  1  1  2  1  1  9  0]\n",
            " [ 1  0  0  0  2  0  0  0  0 11]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7ffb79cd3290>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Il valore dell'accuracy è aumentato fino a 0.64. Il modello è migliorato notevolmente rispetto a prima. \n",
        "Implemetando ulteriori features e lavorando con altri classificatori si potrebbe forse giungere a risultati migliori."
      ],
      "metadata": {
        "id": "-o55Nt2D77FT"
      }
    }
  ]
}